import json
import os
import re
import time
from datetime import datetime, timezone
from pathlib import Path

import requests

HORIZONS_URL = "https://ssd.jpl.nasa.gov/api/horizons.api"
UA = "MCS-Education-EphemerisBot/1.2"

CENTER = "@0"
REF_SYSTEM = "ICRF"
REF_PLANE = "FRAME"
OUT_UNITS = "AU-D"
VEC_TABLE = "2"
TIME_TYPE = "UT"

LAUNCH_TIME = "1977-08-20 14:29:00"

MAJOR_BODIES = [
    ("Sun", 10),
    ("Mercury", 199),
    ("Venus", 299),
    ("Earth", 399),
    ("Mars", 499),
    ("Jupiter", 599),
    ("Saturn", 699),
    ("Uranus", 799),
    ("Neptune", 899),
]

VOYAGER_2_ID = -32

HTTP_TIMEOUT_S = 120
RETRIES = 5
BACKOFF_S = 1.8
DELAY_BETWEEN_CALLS_S = 0.25
MAX_SAMPLES_PER_CALL = 2000

MONTH = {
    "JAN": 1, "FEB": 2, "MAR": 3, "APR": 4, "MAY": 5, "JUN": 6,
    "JUL": 7, "AUG": 8, "SEP": 9, "OCT": 10, "NOV": 11, "DEC": 12
}

EARLIEST_RE = re.compile(
    r'prior to A\.D\. (\d{4})-([A-Z]{3})-(\d{2}) (\d{2}):(\d{2}):(\d{2})(?:\.(\d+))? UT'
)

def q(s: str) -> str:
    return f"'{s}'"

class StartTooEarly(Exception):
    def __init__(self, earliest_dt: datetime, msg: str):
        super().__init__(msg)
        self.earliest_dt = earliest_dt

def parse_utcish(s: str) -> datetime:
    return datetime.strptime(s, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)

def fmt_utcish(dt: datetime) -> str:
    dt = dt.astimezone(timezone.utc).replace(microsecond=0)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def step_seconds(step: str) -> int:
    m = re.match(r"^\s*(\d+)\s*([dm])\s*$", step.strip(), re.IGNORECASE)
    if not m:
        raise ValueError(f"Unsupported STEP_SIZE: {step}")
    n = int(m.group(1))
    u = m.group(2).lower()
    if u == "d":
        return n * 86400
    if u == "m":
        return n * 60
    raise ValueError(f"Unsupported STEP_SIZE unit: {step}")

def stop_time_today_00z() -> str:
    d = datetime.now(timezone.utc).date()
    return f"{d.isoformat()} 00:00:00"

def ensure_dir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)

def write_json(path: Path, obj: dict) -> None:
    ensure_dir(path.parent)
    tmp = path.with_suffix(path.suffix + ".tmp")
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, separators=(",", ":"))
        f.write("\n")
    os.replace(tmp, path)

def parse_earliest_from_error(err: str) -> datetime | None:
    m = EARLIEST_RE.search(err or "")
    if not m:
        return None
    yyyy, mon, dd, hh, mm, ss, frac = m.groups()
    dt = datetime(
        int(yyyy),
        MONTH.get(mon, 1),
        int(dd),
        int(hh),
        int(mm),
        int(ss),
        tzinfo=timezone.utc,
    )
    dt = dt.replace(microsecond=0) + timedelta_seconds(1)
    return dt

def timedelta_seconds(s: int) -> datetime:
    return datetime.fromtimestamp(s, tz=timezone.utc) - datetime.fromtimestamp(0, tz=timezone.utc)

def request_json(params: dict) -> dict:
    last = None
    for i in range(RETRIES):
        try:
            r = requests.get(HORIZONS_URL, params=params, timeout=HTTP_TIMEOUT_S, headers={"User-Agent": UA})
            r.raise_for_status()
            return r.json()
        except Exception as e:
            last = e
            if i == RETRIES - 1:
                break
            time.sleep(BACKOFF_S * (2 ** i))
    raise RuntimeError(f"Horizons request failed: {last}")

def extract_block(result: str) -> str:
    i0 = result.find("$$SOE")
    i1 = result.find("$$EOE")
    if i0 < 0 or i1 < 0 or i1 <= i0:
        snippet = result.strip().replace("\r", "")[:1200]
        raise RuntimeError("Missing $$SOE/$$EOE. " + snippet)
    return result[i0 + 5 : i1].strip()

def parse_vectors(block: str):
    t = []
    pv = []
    for raw in block.splitlines():
        line = raw.strip()
        if not line or not re.match(r"^\d", line):
            continue
        parts = [p.strip() for p in line.split(",")]
        try:
            if len(parts) >= 8:
                jd = float(parts[0])
                x, y, z, vx, vy, vz = map(float, parts[2:8])
            elif len(parts) >= 7:
                jd = float(parts[0])
                x, y, z, vx, vy, vz = map(float, parts[1:7])
            else:
                continue
        except ValueError:
            continue
        t.append(jd)
        pv.extend([x, y, z, vx, vy, vz])
    if len(t) < 2 or len(pv) != len(t) * 6:
        raise RuntimeError("Parsed too few samples.")
    return t, pv

def horizons_vectors_once(command: int, start_time: str, stop_time: str, step_size: str):
    params = {
        "format": "json",
        "EPHEM_TYPE": q("VECTORS"),
        "MAKE_EPHEM": q("YES"),
        "OBJ_DATA": q("NO"),
        "COMMAND": q(str(command)),
        "CENTER": q(CENTER),
        "START_TIME": q(start_time),
        "STOP_TIME": q(stop_time),
        "STEP_SIZE": q(step_size),
        "REF_SYSTEM": q(REF_SYSTEM),
        "REF_PLANE": q(REF_PLANE),
        "OUT_UNITS": q(OUT_UNITS),
        "VEC_TABLE": VEC_TABLE,
        "CSV_FORMAT": q("YES"),
        "VEC_LABELS": q("NO"),
        "VEC_DELTA_T": q("NO"),
        "VEC_CORR": q("NONE"),
        "TIME_TYPE": q(TIME_TYPE),
    }
    j = request_json(params)
    if isinstance(j, dict) and j.get("error"):
        err = str(j["error"])
        earliest = parse_earliest_from_error(err)
        if earliest is not None:
            raise StartTooEarly(earliest, err)
        raise RuntimeError(err)
    result = j.get("result")
    if not isinstance(result, str):
        raise RuntimeError("Missing result field.")
    block = extract_block(result)
    t, pv = parse_vectors(block)
    sig = j.get("signature")
    if not isinstance(sig, dict):
        sig = {}
    return t, pv, sig

def horizons_vectors_chunked(command: int, start_time: str, stop_time: str, step_size: str):
    step_s = step_seconds(step_size)
    max_span_s = step_s * (MAX_SAMPLES_PER_CALL - 1)

    start_dt = parse_utcish(start_time)
    stop_dt = parse_utcish(stop_time)

    all_t = []
    all_pv = []
    sig_any = {}

    while start_dt < stop_dt:
        chunk_stop = start_dt + timedelta_seconds(max_span_s)
        if chunk_stop > stop_dt:
            chunk_stop = stop_dt

        s = fmt_utcish(start_dt)
        e = fmt_utcish(chunk_stop)

        try:
            t, pv, sig = horizons_vectors_once(command, s, e, step_size)
        except StartTooEarly as ex:
            if ex.earliest_dt >= stop_dt:
                raise RuntimeError(str(ex))
            start_dt = ex.earliest_dt
            continue

        if not all_t:
            all_t = t
            all_pv = pv
            sig_any = sig_any or sig
        else:
            last = all_t[-1]
            idx0 = 0
            while idx0 < len(t) and t[idx0] <= last + 1e-10:
                idx0 += 1
            if idx0 < len(t):
                all_t.extend(t[idx0:])
                all_pv.extend(pv[idx0 * 6:])

        time.sleep(DELAY_BETWEEN_CALLS_S)

        if chunk_stop == start_dt:
            break
        start_dt = chunk_stop

    if len(all_t) < 2 or len(all_pv) != len(all_t) * 6:
        raise RuntimeError("Chunked parse produced invalid output.")
    return all_t, all_pv, sig_any

def now_iso() -> str:
    return datetime.now(timezone.utc).replace(microsecond=0).isoformat()

def main():
    repo_root = Path(__file__).resolve().parents[2]
    out_root = repo_root / "NASA_Data" / "events_in_our_solar_system" / "output" / "voyager2"
    ephem_dir = out_root / "ephemeris"
    ensure_dir(ephem_dir)

    stop_time = stop_time_today_00z()

    t_ref = None
    objects = {}
    sig_any = {}

    for name, spkid in MAJOR_BODIES:
        t, pv, sig = horizons_vectors_chunked(spkid, LAUNCH_TIME, stop_time, "5 d")
        if t_ref is None:
            t_ref = t
        else:
            if len(t) != len(t_ref):
                raise RuntimeError(f"Time grid mismatch: {name}")
            for a, b in zip(t, t_ref):
                if abs(a - b) > 1e-10:
                    raise RuntimeError(f"Time grid mismatch: {name}")
        objects[str(spkid)] = {"name": name, "pv": pv}
        sig_any = sig_any or sig

    planets_json = {
        "schema": "mcs-ephem-multi-v1",
        "t_jd": t_ref,
        "objects": objects,
        "meta": {
            "generated_at": now_iso(),
            "source": {"name": "JPL Horizons", "service": HORIZONS_URL},
            "frame": {
                "center": CENTER,
                "ref_system": REF_SYSTEM,
                "ref_plane": REF_PLANE,
                "out_units": OUT_UNITS,
                "time_type": TIME_TYPE,
                "vec_table": VEC_TABLE,
            },
            "signature": sig_any,
        },
    }
    write_json(ephem_dir / "planets_5d.json", planets_json)

    t_v, pv_v, sig_v = horizons_vectors_chunked(VOYAGER_2_ID, LAUNCH_TIME, stop_time, "1 d")
    voyager_json = {
        "schema": "mcs-ephem-v1",
        "t_jd": t_v,
        "pv": pv_v,
        "meta": {
            "generated_at": now_iso(),
            "source": {"name": "JPL Horizons", "service": HORIZONS_URL},
            "frame": {
                "center": CENTER,
                "ref_system": REF_SYSTEM,
                "ref_plane": REF_PLANE,
                "out_units": OUT_UNITS,
                "time_type": TIME_TYPE,
                "vec_table": VEC_TABLE,
            },
            "object": {"name": "Voyager 2", "spkid": VOYAGER_2_ID},
            "signature": sig_v,
        },
    }
    write_json(ephem_dir / "voyager2_1d.json", voyager_json)

    jup_start = "1979-06-25 00:00:00"
    jup_stop  = "1979-07-20 00:00:00"
    sat_start = "1981-08-10 00:00:00"
    sat_stop  = "1981-09-05 00:00:00"
    ura_start = "1986-01-10 00:00:00"
    ura_stop  = "1986-02-05 00:00:00"
    nep_start = "1989-08-10 00:00:00"
    nep_stop  = "1989-09-05 00:00:00"

    for ds_id, s, e, fn in [
        ("voyager2_jupiter_30m", jup_start, jup_stop, "voyager2_jupiter_30m.json"),
        ("voyager2_saturn_30m", sat_start, sat_stop, "voyager2_saturn_30m.json"),
        ("voyager2_uranus_30m", ura_start, ura_stop, "voyager2_uranus_30m.json"),
        ("voyager2_neptune_30m", nep_start, nep_stop, "voyager2_neptune_30m.json"),
    ]:
        t_hi, pv_hi, sig_hi = horizons_vectors_chunked(VOYAGER_2_ID, s, e, "30 m")
        hi_json = {
            "schema": "mcs-ephem-v1",
            "t_jd": t_hi,
            "pv": pv_hi,
            "meta": {
                "generated_at": now_iso(),
                "source": {"name": "JPL Horizons", "service": HORIZONS_URL},
                "frame": {
                    "center": CENTER,
                    "ref_system": REF_SYSTEM,
                    "ref_plane": REF_PLANE,
                    "out_units": OUT_UNITS,
                    "time_type": TIME_TYPE,
                    "vec_table": VEC_TABLE,
                },
                "object": {"name": "Voyager 2", "spkid": VOYAGER_2_ID},
                "window": {"start": s, "stop": e, "step": "30 m"},
                "signature": sig_hi,
            },
        }
        write_json(ephem_dir / fn, hi_json)

    manifest = {
        "schema": "mcs-ephem-manifest-v1",
        "generated_at": now_iso(),
        "source": {"name": "JPL Horizons", "service": HORIZONS_URL},
        "frame": {
            "center": CENTER,
            "ref_system": REF_SYSTEM,
            "ref_plane": REF_PLANE,
            "out_units": OUT_UNITS,
            "time_type": TIME_TYPE,
            "vec_table": VEC_TABLE,
        },
        "datasets": [
            {"id": "planets_5d", "file": "ephemeris/planets_5d.json"},
            {"id": "voyager2_1d", "file": "ephemeris/voyager2_1d.json"},
            {"id": "voyager2_jupiter_30m", "file": "ephemeris/voyager2_jupiter_30m.json"},
            {"id": "voyager2_saturn_30m", "file": "ephemeris/voyager2_saturn_30m.json"},
            {"id": "voyager2_uranus_30m", "file": "ephemeris/voyager2_uranus_30m.json"},
            {"id": "voyager2_neptune_30m", "file": "ephemeris/voyager2_neptune_30m.json"}
        ],
    }
    write_json(out_root / "manifest.json", manifest)

if __name__ == "__main__":
    main()
